# UXMCP - Universal eXtensible Model Context Protocol Manager

<div align="center">

[![Docker](https://img.shields.io/badge/Docker-Ready-blue)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green)](https://fastapi.tiangolo.com)
[![React](https://img.shields.io/badge/React-18+-blue)](https://reactjs.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-7.0+-green)](https://www.mongodb.com/)
[![MCP](https://img.shields.io/badge/MCP-Compatible-orange)](https://modelcontextprotocol.io)

</div>

UXMCP est une plateforme complÃ¨te de gestion de services MCP (Model Context Protocol) qui permet de crÃ©er, dÃ©ployer et gÃ©rer dynamiquement des services pour les agents IA. Avec son interface web intuitive et son agent crÃ©ateur autonome, UXMCP rÃ©volutionne la faÃ§on de construire des outils pour l'IA.

## ğŸŒŸ FonctionnalitÃ©s Principales

### ğŸ¤– Agent CrÃ©ateur Autonome
- **CrÃ©ation automatique de services** par simple description en langage naturel
- **Correction automatique des erreurs** - l'agent debug et corrige le code jusqu'Ã  ce qu'il fonctionne
- **Installation automatique des dÃ©pendances** - dÃ©tecte et installe les packages manquants
- **GÃ©nÃ©ration de documentation** et schÃ©mas de sortie

### ğŸ”§ Gestion Dynamique de Services
- **3 types de services MCP** :
  - **Tools** : Actions et calculs avec schÃ©mas de sortie structurÃ©s
  - **Resources** : Fournisseurs de contenu avec types MIME
  - **Prompts** : Templates dynamiques pour les LLMs
- **Activation/dÃ©sactivation en temps rÃ©el** sans redÃ©marrage
- **Routes HTTP dynamiques** ajoutÃ©es/retirÃ©es Ã  la volÃ©e
- **IntÃ©gration MCP native** pour tous les services actifs

### ğŸ¤ SystÃ¨me d'Agents IA
- **CrÃ©ation d'agents personnalisÃ©s** avec profils LLM configurables
- **AccÃ¨s aux outils MCP** - les agents peuvent utiliser tous les services actifs
- **Routes dynamiques** - chaque agent a son endpoint HTTP unique
- **Support streaming** pour les rÃ©ponses en temps rÃ©el

### ğŸ’¬ Interface de Chat IntÃ©grÃ©e
- **Chat avec diffÃ©rents profils LLM** (GPT-4, Claude, etc.)
- **Historique des conversations** persistant
- **Support du streaming** pour les rÃ©ponses longues
- **Interface moderne** avec Ant Design

### ğŸ§  Meta Chat - Routage Intelligent
- **Analyse automatique des intentions** - Comprend ce que vous voulez faire
- **SÃ©lection ou crÃ©ation d'agent** - Trouve l'agent parfait ou en crÃ©e un nouveau
- **RÃ©ponses directes ou dÃ©lÃ©guÃ©es** - RÃ©pond directement ou utilise un agent spÃ©cialisÃ©
- **Visualisation HTML** des rÃ©ponses complexes
- **Aucune configuration requise** - Posez simplement votre question !

### ğŸ“Š SystÃ¨me de Logs CentralisÃ©
- **Logs structurÃ©s dans MongoDB** avec traÃ§abilitÃ© complÃ¨te
- **API de requÃªte puissante** avec filtres et agrÃ©gations
- **Suivi d'exÃ©cution** par service et par execution_id
- **Niveaux de log** configurables (DEBUG, INFO, WARNING, ERROR)

### ğŸ¨ Interface Web React
- **Design moderne** avec Ant Design 5
- **Navigation intuitive** entre services, agents, profils et logs
- **Ã‰diteur de code** avec coloration syntaxique
- **Tests intÃ©grÃ©s** pour valider les services

## ğŸš€ Installation Rapide

### PrÃ©requis
- Docker et Docker Compose
- Ports disponibles : 8000 (API), 5173 (Frontend), 27018 (MongoDB)

### Installation

```bash
# 1. Cloner le repository
git clone https://github.com/yourusername/uxmcp.git
cd uxmcp

# 2. Lancer avec Docker Compose
make up

# 3. AccÃ©der Ã  l'interface
open http://localhost:5173
```

## ğŸ“‹ Guide d'Utilisation

### CrÃ©ation Automatique de Service par IA

1. Allez dans l'onglet "Services"
2. Cliquez sur "Create with AI"
3. DÃ©crivez votre service en langage naturel :
   ```
   "Un service qui extrait le texte d'une page web avec BeautifulSoup"
   ```
4. L'agent va :
   - GÃ©nÃ©rer le code Python
   - Installer les dÃ©pendances nÃ©cessaires
   - Tester et corriger jusqu'Ã  ce que Ã§a fonctionne
   - Activer le service automatiquement

### CrÃ©ation Manuelle d'un Service

#### Exemple : Service Tool (Calculatrice)
```python
def handler(**params):
    operation = params.get('operation', 'add')
    a = float(params.get('a', 0))
    b = float(params.get('b', 0))
    
    if operation == 'add':
        result = a + b
    elif operation == 'multiply':
        result = a * b
    elif operation == 'power':
        result = a ** b
    else:
        return {"error": f"Unknown operation: {operation}"}
    
    return {
        "operation": operation,
        "a": a,
        "b": b,
        "result": result
    }
```

#### Exemple : Service Resource (Documentation)
```python
def handler(**params):
    doc_id = params.get('id', 'default')
    
    content = f"""# Documentation for {doc_id}
    
This is a sample resource providing documentation.
Generated at: {datetime.datetime.utcnow().isoformat()}
"""
    
    return {
        "content": content,
        "mimeType": "text/markdown"
    }
```

#### Exemple : Service Prompt (Template)
```python
def handler(**params):
    language = params.get('language', 'Python')
    task = params.get('task', 'explain this code')
    
    template = f"""You are an expert {language} developer.

Task: {task}

Please provide a detailed response following best practices."""
    
    return {"template": template}
```

### CrÃ©ation d'un Agent IA

1. CrÃ©ez un profil LLM dans "LLM Profiles"
2. Allez dans "Agents" et cliquez "Create New Agent"
3. Configurez l'agent :
   - **Name** : Nom unique de l'agent
   - **System Prompt** : Instructions pour l'agent
   - **LLM Profile** : Profil Ã  utiliser
   - **Tools** : Services MCP accessibles

### Utilisation du Meta Chat

Le Meta Chat est votre assistant intelligent qui comprend vos besoins et trouve ou crÃ©e automatiquement l'agent parfait pour y rÃ©pondre.

#### Comment Ã§a marche ?

1. **Posez votre question** en langage naturel
2. Le systÃ¨me **analyse votre intention**
3. Il **trouve l'agent adaptÃ©** ou en **crÃ©e un nouveau** si nÃ©cessaire
4. L'agent **exÃ©cute la tÃ¢che** et retourne la rÃ©ponse

#### Exemples d'utilisation

```bash
# Demander la mÃ©tÃ©o (trouvera ou crÃ©era un agent mÃ©tÃ©o)
curl -X POST http://localhost:8000/meta-chat/query \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Quel temps fait-il Ã  Paris ?",
    "llm_profile": "gpt-4"
  }'

# Faire des calculs (utilisera un agent calculatrice)
curl -X POST http://localhost:8000/meta-chat/query \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Calcule 25% de 180 euros",
    "llm_profile": "gpt-4"
  }'

# Demande complexe (crÃ©era un agent spÃ©cialisÃ© si besoin)
curl -X POST http://localhost:8000/meta-chat/query \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Analyse les performances de mon site web example.com",
    "llm_profile": "gpt-4"
  }'
```

### Utilisation des Services

#### Via HTTP
```bash
# Service GET
curl http://localhost:8000/api/calculator?operation=add&a=5&b=3

# Service POST
curl -X POST http://localhost:8000/api/web_extractor \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'
```

#### Via MCP
Les services actifs sont exposÃ©s sur `http://localhost:8000/mcp` pour les clients MCP.

#### Via Agents
```bash
curl -X POST http://localhost:8000/agents/my-agent/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Calculate 5 + 3"}'
```

## ğŸ—ï¸ Architecture

```
UXMCP/
â”œâ”€â”€ backend/                  # API FastAPI
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/             # Endpoints REST
â”‚   â”‚   â”‚   â”œâ”€â”€ services.py  # CRUD services
â”‚   â”‚   â”‚   â”œâ”€â”€ agents.py    # Gestion agents
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py      # Interface chat
â”‚   â”‚   â”‚   â”œâ”€â”€ logs.py      # API logs
â”‚   â”‚   â”‚   â””â”€â”€ llm.py       # Profils LLM
â”‚   â”‚   â”œâ”€â”€ core/            # Core systÃ¨me
â”‚   â”‚   â”‚   â”œâ”€â”€ dynamic_router.py    # Routes dynamiques
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp_manager.py       # IntÃ©gration MCP
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_tools.py       # Outils pour agents
â”‚   â”‚   â”‚   â””â”€â”€ mongodb_logger.py    # SystÃ¨me de logs
â”‚   â”‚   â”œâ”€â”€ models/          # ModÃ¨les Pydantic
â”‚   â”‚   â””â”€â”€ services/        # Logic mÃ©tier
â”‚   â”‚       â”œâ”€â”€ agent_service.py     # Agent crÃ©ateur
â”‚   â”‚       â””â”€â”€ service_crud.py      # CRUD services
â”‚   â””â”€â”€ tests/               # Tests unitaires
â”œâ”€â”€ frontend/                # Interface React
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/      # Composants UI
â”‚       â”‚   â”œâ”€â”€ ServiceList.jsx
â”‚       â”‚   â”œâ”€â”€ AgentList.jsx
â”‚       â”‚   â”œâ”€â”€ ChatInterface.jsx
â”‚       â”‚   â””â”€â”€ LogViewer.jsx
â”‚       â”œâ”€â”€ services/        # API client
â”‚       â””â”€â”€ hooks/           # React hooks
â”œâ”€â”€ examples/                # Services d'exemple
â””â”€â”€ docker-compose.yml       # Configuration Docker
```

## ğŸ”§ Configuration

### Variables d'Environnement

CrÃ©ez un fichier `.env` dans le dossier `backend` :

```env
# MongoDB
MONGODB_URL=mongodb://mongo:27017
DATABASE_NAME=uxmcp

# API
MCP_SERVER_URL=http://localhost:8000/mcp
LOG_LEVEL=INFO
CORS_ORIGINS=["http://localhost:5173"]

# Optionnel : ClÃ©s API pour les LLMs
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
```

### Configuration des Profils LLM

Les profils LLM peuvent Ãªtre configurÃ©s via l'interface ou l'API :

```json
{
  "name": "gpt-4-turbo",
  "provider": "openai",
  "model": "gpt-4-turbo-preview",
  "api_key": "sk-...",
  "endpoint": "https://api.openai.com/v1/chat/completions",
  "max_tokens": 4096,
  "temperature": 0.7,
  "mode": "json",  // Pour les rÃ©ponses structurÃ©es
  "active": true
}
```

## ğŸ“š API Reference

### Services
- `GET /services` - Liste tous les services
- `POST /services` - CrÃ©er un service
- `GET /services/{id}` - DÃ©tails d'un service
- `PUT /services/{id}` - Mettre Ã  jour un service
- `DELETE /services/{id}` - Supprimer un service
- `POST /services/{id}/activate` - Activer un service
- `POST /services/{id}/deactivate` - DÃ©sactiver un service
- `POST /services/{id}/test` - Tester un service

### Agents
- `GET /agents` - Liste tous les agents
- `POST /agents` - CrÃ©er un agent
- `POST /agents/{name}/chat` - Discuter avec un agent
- `POST /agent/create-service` - CrÃ©er un service via IA

### Logs
- `GET /logs/latest` - Logs rÃ©cents
- `GET /logs/services/{service_id}` - Logs d'un service
- `GET /logs/search` - Recherche dans les logs
- `GET /logs/stats` - Statistiques des logs

### Chat
- `GET /chat/profiles` - Profils disponibles
- `POST /chat/stream` - Chat avec streaming
- `GET /chat/history` - Historique des conversations

### Meta Chat
- `POST /meta-chat/query` - Envoyer une requÃªte au systÃ¨me intelligent
  - Body: `{"message": "votre question", "llm_profile": "nom_profil"}`
  - Response: RÃ©ponse formatÃ©e avec agent utilisÃ©/crÃ©Ã©

## ğŸ› ï¸ Commandes Make

```bash
make help          # Afficher l'aide
make up            # DÃ©marrer tous les services
make down          # ArrÃªter tous les services
make logs          # Suivre les logs
make status        # VÃ©rifier le statut
make test          # Lancer les tests
make build         # Construire les images Docker
make clean         # Nettoyer volumes et images

# DÃ©veloppement
make shell-api     # Shell dans le container API
make shell-mongo   # Shell MongoDB
make import-examples  # Importer les exemples
```

## ğŸ§ª Tests

```bash
# Tous les tests
make test

# Tests spÃ©cifiques
docker-compose exec api pytest tests/unit/test_models.py -v

# Avec couverture
docker-compose exec api pytest --cov=app
```

## ğŸ“– Guides AvancÃ©s

### Ajouter un Nouveau Type de Service

1. Ã‰tendre le modÃ¨le dans `models/service.py`
2. Mettre Ã  jour `mcp_manager.py` pour l'enregistrement
3. Ajouter le support UI dans `ServiceForm.jsx`
4. Documenter dans `service_documentation.py`

### CrÃ©er un Provider LLM PersonnalisÃ©

1. ImplÃ©menter l'interface dans `services/llm_service.py`
2. Ajouter la configuration dans `models/llm.py`
3. Tester avec l'agent crÃ©ateur

### DÃ©bugger un Service

1. VÃ©rifier les logs : `make logs`
2. Consulter les logs MongoDB via l'API
3. Utiliser l'endpoint de test dans l'UI
4. Examiner `/debug/mcp/info` pour l'Ã©tat MCP

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! 

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit (`git commit -m 'Add AmazingFeature'`)
4. Push (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Guidelines
- Suivre les conventions Python (PEP 8)
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Mettre Ã  jour la documentation
- Utiliser des messages de commit descriptifs

## ğŸ“„ License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ”— Ressources

- [Model Context Protocol](https://modelcontextprotocol.io) - SpÃ©cification MCP
- [FastAPI](https://fastapi.tiangolo.com) - Framework API
- [FastMCP](https://github.com/jlowin/fastmcp) - ImplÃ©mentation Python MCP
- [React](https://reactjs.org) - Framework UI
- [Ant Design](https://ant.design) - Composants UI
- [MongoDB](https://www.mongodb.com) - Base de donnÃ©es

## ğŸ™ Remerciements

- L'Ã©quipe Anthropic pour le Model Context Protocol
- La communautÃ© FastAPI pour l'excellent framework
- Tous les contributeurs du projet

---

<div align="center">
Made with â¤ï¸ by the UXMCP Team
</div>